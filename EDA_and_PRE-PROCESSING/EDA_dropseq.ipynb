{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project - validation data to be given at the end of the course & data not to be shared\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on Unfiltered DropSeq HCC and MCF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MCF7_unfiltered = pd.read_csv(\"DropSeq/MCF7_Filtered_Normalised_3000_Data_train.txt\", delimiter=' ').T\n",
    "print(\"Dataframe dimensions:\", np.shape(df_MCF7_unfiltered))\n",
    "df_MCF7_unfiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MCF7_unfiltered.info()\n",
    "df_MCF7_unfiltered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HCC_unfiltered = pd.read_csv(\"DropSeq/HCC1806_Filtered_Normalised_3000_Data_train.txt\", delimiter=' ').T\n",
    "print(\"Dataframe dimensions:\", np.shape(df_HCC_unfiltered))\n",
    "df_HCC_unfiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HCC_unfiltered.info()\n",
    "df_HCC_unfiltered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sets of gene names (column names)\n",
    "genes_1 = set(df_MCF7_unfiltered.columns)\n",
    "genes_2 = set(df_HCC_unfiltered.columns)\n",
    "\n",
    "# Genes only in grouped_sums_1\n",
    "unique_to_1 = genes_1 - genes_2\n",
    "\n",
    "# Genes only in grouped_sums_2\n",
    "unique_to_2 = genes_2 - genes_1\n",
    "\n",
    "# Union of all unique genes (not shared)\n",
    "not_in_common = unique_to_1.union(unique_to_2)\n",
    "\n",
    "# Output\n",
    "print(f\"Genes only in MCF7 dataset: {len(unique_to_1)}\")\n",
    "print(f\"Genes only in HCC dataset: {len(unique_to_2)}\")\n",
    "print(f\"Total genes not in common: {len(not_in_common)}\")\n",
    "print(f\"{not_in_common}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISSING VALUES, DUPLICATES and SPARSITY ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicates and missing values\n",
    "# Percentage of missing values for the whole dataset\n",
    "print(\"MCF7 dataset\")\n",
    "total_cells = (df_MCF7_unfiltered.shape[0] * df_MCF7_unfiltered.shape[1])\n",
    "total_missing = df_MCF7_unfiltered.isnull().sum().sum()\n",
    "missing_percentage_total = (total_missing / total_cells) * 100\n",
    "print(f\"Total missing values in MCF7 dataset: {missing_percentage_total:.2f}%\")\n",
    "\n",
    "# Missing values per column (only where missing values exist)\n",
    "missing_per_column = df_MCF7_unfiltered.isnull().sum()\n",
    "\n",
    "print(\"\\nColumns with missing values (percentage):\")\n",
    "print(missing_per_column)\n",
    "\n",
    "print(f\"count of duplicates: {df_MCF7_unfiltered.duplicated().sum()}\")\n",
    "# Remove if needed\n",
    "df = df_MCF7_unfiltered.drop_duplicates()\n",
    "\n",
    "print(\"\\nHCC dataset\")\n",
    "# checking for duplicates and missing values\n",
    "# Percentage of missing values for the whole dataset\n",
    "total_cells = (df_HCC_unfiltered.shape[0] * df_HCC_unfiltered.shape[1])\n",
    "total_missing = df_HCC_unfiltered.isnull().sum().sum()\n",
    "missing_percentage_total = (total_missing / total_cells) * 100\n",
    "print(f\"Total missing values in HCC dataset: {missing_percentage_total:.2f}%\")\n",
    "\n",
    "# Missing values per column (only where missing values exist)\n",
    "missing_per_column = df_HCC_unfiltered.isnull().sum()\n",
    "\n",
    "print(\"\\nColumns with missing values (percentage):\")\n",
    "print(missing_per_column)\n",
    "\n",
    "print(f\"count of duplicates: {df_HCC_unfiltered.duplicated().sum()}\")\n",
    "# Remove if needed\n",
    "df = df_HCC_unfiltered.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MCF7 dataset\")\n",
    "# analyse the transposed dataset with samples as columns and genes as rows\n",
    "print(f\"count of duplicates: {df_MCF7_unfiltered.T.duplicated().sum()}\")\n",
    "\n",
    "# Find duplicated rows\n",
    "duplicated_rows = df_MCF7_unfiltered.T[df_MCF7_unfiltered.T.duplicated(keep=False)]\n",
    "\n",
    "# Print the sample names (index labels) of duplicated rows\n",
    "if not duplicated_rows.empty:\n",
    "    print(\"Duplicated Columns of Genes found:\")\n",
    "    print(duplicated_rows.index.tolist())\n",
    "else:\n",
    "    print(\"No duplicated samples found.\")\n",
    "\n",
    "print(\"\\n HCC dataset\")\n",
    "# analyse the transposed dataset with samples as columns and genes as rows\n",
    "print(f\"count of duplicates: {df_HCC_unfiltered.T.duplicated().sum()}\")\n",
    "\n",
    "# Find duplicated rows\n",
    "duplicated_rows2 = df_HCC_unfiltered.T[df_HCC_unfiltered.T.duplicated(keep=False)]\n",
    "\n",
    "# Print the sample names (index labels) of duplicated rows\n",
    "if not duplicated_rows2.empty:\n",
    "    print(\"Duplicated Columns of Genes found:\")\n",
    "    print(duplicated_rows2.index.tolist())\n",
    "else:\n",
    "    print(\"No duplicated samples found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although all samples are not identiccally zero for all genes (no samples) are redundant, the same cannot be said for the above genes which aren't expressed for any sample. Thus, if one considered only this dataset, the latter should be removed since they increase dimensionality without any additional info, but since the latter genes might not be identically zero for the other datasets, they will be kept for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARSITY and GENE EXPRESSION by gene's expression mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the sparsity and distribution of the dataset \n",
    "non_sparse_genes = [i for i in df_MCF7_unfiltered.columns if df_MCF7_unfiltered[i].mean() >= 1] # non-sparse genes have mean greater than 1 considering also std\n",
    "non_sparse_genes = sorted(non_sparse_genes, key = lambda x: df_MCF7_unfiltered[x].mean(), reverse=True) # sort according to sparsity and use then for visual\n",
    "print(f\"Number of non-sparse genes in MCF7 dataset: {len(non_sparse_genes)} or {len(non_sparse_genes)/len(df_MCF7_unfiltered.columns):.4}% of all genes\")\n",
    "\n",
    "# understanding the sparsity and distribution of the dataset \n",
    "non_sparse_genes2 = [i for i in df_HCC_unfiltered.columns if df_HCC_unfiltered[i].mean() >= 1] # non-sparse genes have mean greater than 1 considering also std\n",
    "non_sparse_genes2 = sorted(non_sparse_genes2, key = lambda x: df_HCC_unfiltered[x].mean(), reverse=True) # sort according to sparsity and use then for visual\n",
    "print(f\"Number of non-sparse genes in HCC dataset: {len(non_sparse_genes2)} or {len(non_sparse_genes2)/len(df_HCC_unfiltered.columns):.4}% of all genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "print(f\"TOP non-sparse genes in MCF7 dataset: {non_sparse_genes[:n]}\")\n",
    "print(f\"TOP non-sparse genes in HCC dataset: {non_sparse_genes2[:n]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = int(n/2), nrows = 2, figsize = (30,15))\n",
    "\n",
    "for i, col in enumerate(non_sparse_genes[:n]):\n",
    "    # Plot histogram for df_MCF7_unfiltered\n",
    "    if col in df_MCF7_unfiltered.columns and col in df_HCC_unfiltered.columns:\n",
    "        ax.flat[i].hist(df_MCF7_unfiltered[col], bins=30, alpha=0.5, edgecolor='black', density=True, label='MCF7')\n",
    "        # Plot histogram for df2\n",
    "        ax.flat[i].hist(df_HCC_unfiltered[col], bins=30, alpha=0.5, edgecolor='black', density=True, label='HCC')\n",
    "        \n",
    "        # KDE plots for both\n",
    "        sns.kdeplot(df_MCF7_unfiltered[col], ax=ax.flat[i], bw_adjust=1, color='blue', label='MCF7 KDE')\n",
    "        sns.kdeplot(df_HCC_unfiltered[col], ax=ax.flat[i], bw_adjust=1, color='red', label='HCC KDE')\n",
    "\n",
    "        ax.flat[i].set_xlabel('')\n",
    "        ax.flat[i].set_title(f\"{col}\\nMCF7 μ: {df_MCF7_unfiltered[col].mean():.0f}, HCC μ: {df_HCC_unfiltered[col].mean():.0f}\")\n",
    "        ax.flat[i].legend()\n",
    "\n",
    "plt.suptitle(\"distribution of top 10 non-sparse genes in MCF7 dataset and comparison with HCC dataset\", fontsize = 24)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30, 15))\n",
    "\n",
    "for i, col in enumerate(non_sparse_genes[:n]):\n",
    "    if col in df_MCF7_unfiltered.columns and col in df_HCC_unfiltered.columns:\n",
    "        combined_df = pd.DataFrame({\n",
    "            'value': pd.concat([df_MCF7_unfiltered[col], df_HCC_unfiltered[col]]),\n",
    "            'dataset': ['MCF7'] * len(df_MCF7_unfiltered) + ['HCC'] * len(df_HCC_unfiltered)\n",
    "        })\n",
    "        \n",
    "        # Violin plot\n",
    "        sns.violinplot( data=combined_df, x='dataset', y='value', hue='dataset',  palette=['lightblue', 'lightgreen'],  ax=ax.flat[i],  inner=None,  linewidth=1,  legend=False)\n",
    "        # Boxplot overlay\n",
    "        sns.boxplot(    data=combined_df, x='dataset',  y='value',  hue='dataset', palette=['lightblue', 'lightgreen'], ax=ax.flat[i],   width=0.2, showcaps=True, fliersize=2, legend=False)\n",
    "\n",
    "        # Remove default labels\n",
    "        ax.flat[i].set_xlabel('')\n",
    "        ax.flat[i].set_ylabel('')\n",
    "        \n",
    "        # Custom title with means\n",
    "        mcf7_mean = df_MCF7_unfiltered[col].mean()\n",
    "        df2_mean = df_HCC_unfiltered[col].mean()\n",
    "        ax.flat[i].set_title(f\"{col}\\nMCF7 μ: {mcf7_mean:.0f}, HCC μ: {df2_mean:.0f}\")\n",
    "\n",
    "\n",
    "plt.suptitle(\"distribution of top 20 non-sparse genes in MCF7 dataset and comparison with HCC dataset\", fontsize = 16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = int(n/2), nrows = 2, figsize = (30,15))\n",
    "\n",
    "for i, col in enumerate(non_sparse_genes2[:n]):\n",
    "    if col in df_MCF7_unfiltered.columns and col in df_HCC_unfiltered.columns:\n",
    "        # Plot histogram for df_MCF7_unfiltered\n",
    "        ax.flat[i].hist(df_MCF7_unfiltered[col], bins=30, alpha=0.5, edgecolor='black', density=True, label='MCF7')\n",
    "        # Plot histogram for df2\n",
    "        ax.flat[i].hist(df_HCC_unfiltered[col], bins=30, alpha=0.5, edgecolor='black', density=True, label='HCC')\n",
    "        \n",
    "        # KDE plots for both\n",
    "        sns.kdeplot(df_MCF7_unfiltered[col], ax=ax.flat[i], bw_adjust=1, color='blue', label='MCF7 KDE')\n",
    "        sns.kdeplot(df_HCC_unfiltered[col], ax=ax.flat[i], bw_adjust=1, color='red', label='HCC KDE')\n",
    "\n",
    "        ax.flat[i].set_xlabel('')\n",
    "        ax.flat[i].set_title(f\"{col}, MCF7 μ: {df_MCF7_unfiltered[col].mean():.0f}, HCC μ: {df_HCC_unfiltered[col].mean():.0f}\")\n",
    "        ax.flat[i].legend()\n",
    "\n",
    "plt.suptitle(\"distribution of top 10 non-sparse genes in HCC dataset and comparison with MCF7 dataset\", fontsize = 24)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30, 15))\n",
    "\n",
    "for i, col in enumerate(non_sparse_genes2[:n]):\n",
    "    if col in df_MCF7_unfiltered.columns and col in df_HCC_unfiltered.columns:\n",
    "        combined_df = pd.DataFrame({\n",
    "            'value': pd.concat([df_MCF7_unfiltered[col], df_HCC_unfiltered[col]]),\n",
    "            'dataset': ['MCF7'] * len(df_MCF7_unfiltered) + ['HCC'] * len(df_HCC_unfiltered)\n",
    "        })\n",
    "        \n",
    "        # Violin plot\n",
    "        sns.violinplot( data=combined_df, x='dataset', y='value', hue='dataset',  palette=['lightblue', 'lightgreen'],  ax=ax.flat[i],  inner=None,  linewidth=1,  legend=False)\n",
    "        # Boxplot overlay\n",
    "        sns.boxplot(    data=combined_df, x='dataset',  y='value',  hue='dataset', palette=['lightblue', 'lightgreen'], ax=ax.flat[i],   width=0.2, showcaps=True, fliersize=2, legend=False)\n",
    "\n",
    "        # Remove default labels\n",
    "        ax.flat[i].set_xlabel('')\n",
    "        ax.flat[i].set_ylabel('')\n",
    "        \n",
    "        # Custom title with means\n",
    "        mcf7_mean = df_MCF7_unfiltered[col].mean()\n",
    "        df2_mean = df_HCC_unfiltered[col].mean()\n",
    "        ax.flat[i].set_title(f\"{col}\\nMCF7 μ: {mcf7_mean:.0f}, HCC μ: {df2_mean:.0f}\")\n",
    "\n",
    "\n",
    "plt.suptitle(\"distribution of top 20 non-sparse genes in HCC dataset and comparison with MCF7 dataset\", fontsize = 16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARSITY by density of zeroes in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Choose a random subset of columns (e.g., 10 columns)\n",
    "num_cols = 500\n",
    "random_cols_1 = np.random.choice(df_MCF7_unfiltered.columns, size=num_cols, replace=False)\n",
    "random_cols_2 = np.random.choice(df_HCC_unfiltered.columns, size=num_cols, replace=False)\n",
    "\n",
    "# Filter both datasets with the same random columns\n",
    "df1_sampled = df_MCF7_unfiltered[random_cols_1]\n",
    "df2_sampled = df_HCC_unfiltered[random_cols_2]\n",
    "\n",
    "# Compute zero masks\n",
    "zero_mask1 = df1_sampled == 0\n",
    "zero_mask2 = df2_sampled == 0\n",
    "\n",
    "# Print sparsity index\n",
    "sparsity1 = zero_mask1.sum().sum() / (df1_sampled.shape[0] * df1_sampled.shape[1])\n",
    "sparsity2 = zero_mask2.sum().sum() / (df2_sampled.shape[0] * df2_sampled.shape[1])\n",
    "\n",
    "print(f\"Dataset MCF7 Sparsity Index: {sparsity1:.4f}\")\n",
    "print(f\"Dataset HCC Sparsity Index: {sparsity2:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Heatmap for Dataset 1\n",
    "plt.subplot(2,1, 1)\n",
    "sns.heatmap(zero_mask1, cbar=False, cmap=sns.color_palette([\"white\", \"blue\"]))\n",
    "plt.title('Zero Values Heatmap - MFC7 Dataset')\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "# Heatmap for Dataset 2\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(zero_mask2, cbar=False, cmap=sns.color_palette([\"white\", \"blue\"]))\n",
    "plt.title('Zero Values Heatmap - HCC Dataset')\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph of sparsity index (number of zeroes) against coutn of such index in the genes\n",
    "# Calculate sparsity index for each gene (column) in both datasets\n",
    "sparsity1 = ((df_MCF7_unfiltered == 0).sum(axis=0) / df_MCF7_unfiltered.shape[0])\n",
    "sparsity2 = (df_HCC_unfiltered == 0).sum(axis=0) / df_HCC_unfiltered.shape[0]\n",
    "\n",
    "# Plot overlayed histograms\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.hist(sparsity1, bins=80, range=(0, 1), edgecolor='black', alpha=0.6, label='MCF7 Dataset', color='blue')\n",
    "plt.hist(sparsity2, bins=80, range=(0, 1), edgecolor='black', alpha=0.6, label='HCC Dataset', color='lightgreen')\n",
    "\n",
    "plt.title(\"Overlayed Histogram of Gene Sparsity Indices\")\n",
    "plt.xlabel(\"Sparsity Index (Fraction of Zero Counts)\")\n",
    "plt.ylabel(\"Number of Genes\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.ylim(0,200)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unfiltered dataset is very sparse so that it makes sense to use dimensionality reduction since the columns corresponding to some genes are almost indetically zero and only then apply clustering. \\n From now on restict analysis to genes with non-zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genes expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total counts per cell (row) for both datasets\n",
    "df1_total_counts = df_MCF7_unfiltered.sum(axis=1)\n",
    "df2_total_counts = df_HCC_unfiltered.sum(axis=1)\n",
    "\n",
    "# Plot overlayed histograms with KDE\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(df1_total_counts, bins=70, kde=True, color='steelblue', label='MCF7 Dataset', alpha=0.6)\n",
    "sns.histplot(df2_total_counts, bins=70, kde=True, color='darkorange', label='HCC Dataset', alpha=0.6)\n",
    "\n",
    "plt.title(\"Overlayed Histogram of Total Gene Counts per Cell\")\n",
    "plt.xlabel(\"Total Counts per Cell\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = df_MCF7_unfiltered.T.columns\n",
    "cell_type = []\n",
    "for name in sample_names:\n",
    "    if \"Norm\" in name:\n",
    "        cell_type.append(\"Norm\")\n",
    "    elif \"Hypo\" in name:\n",
    "        cell_type.append(\"Hypo\")\n",
    "df_MCF7_unfiltered[\"CellType\"] = cell_type\n",
    "\n",
    "sample_names = df_HCC_unfiltered.T.columns\n",
    "cell_type = []\n",
    "for name in sample_names:\n",
    "    if \"Norm\" in name:\n",
    "        cell_type.append(\"Norm\")\n",
    "    elif \"Hypo\" in name:\n",
    "        cell_type.append(\"Hypo\")\n",
    "df_HCC_unfiltered[\"CellType\"] = cell_type\n",
    "\n",
    "print(\"MCF7 dataset\")\n",
    "print(f\"Checking for unbalanced classes \\nNormoxia: {(df_MCF7_unfiltered[\"CellType\"]==\"Norm\").sum()/ len(df_MCF7_unfiltered[\"CellType\"]):.5}%, \\t Hypoxia: {1-(df_MCF7_unfiltered[\"CellType\"]==\"Norm\").sum()/ len(df_MCF7_unfiltered[\"CellType\"]):.5}%\")\n",
    "print(f\"Differnece in absolute count of samples with Normoxia vs (-) Hypoxia: {(df_MCF7_unfiltered[\"CellType\"]==\"Norm\").sum() - (df_MCF7_unfiltered[\"CellType\"]==\"Hypo\").sum()}\")\n",
    "print(\"the classes are almost perfectly balanced \\n\")\n",
    "\n",
    "# Separate the features from the label\n",
    "feature_columns_1 = df_MCF7_unfiltered.columns.difference([\"CellType\"])\n",
    "# Group by the label and sum each group\n",
    "grouped_sums_1 = df_MCF7_unfiltered.groupby(\"CellType\")[feature_columns_1].sum() \n",
    "print(grouped_sums_1.head())\n",
    "\n",
    "print(\"\\nHCC dataset\")\n",
    "print(f\"Checking for unbalanced classes \\nNormoxia: {(df_HCC_unfiltered[\"CellType\"]==\"Norm\").sum()/ len(df_HCC_unfiltered[\"CellType\"]):.5}%, \\t Hypoxia: {1-(df_HCC_unfiltered[\"CellType\"]==\"Norm\").sum()/ len(df_HCC_unfiltered[\"CellType\"]):.5}%\")\n",
    "print(f\"Differnece in absolute count of samples with Normoxia vs (-) Hypoxia: {(df_HCC_unfiltered[\"CellType\"]==\"Norm\").sum() - (df_HCC_unfiltered[\"CellType\"]==\"Hypo\").sum()}\")\n",
    "print(\"the classes are almost perfectly balanced \\n\")\n",
    "\n",
    "# Separate the features from the label\n",
    "feature_columns_2 = df_HCC_unfiltered.columns.difference([\"CellType\"])\n",
    "# Group by the label and sum each group\n",
    "grouped_sums_2 = df_HCC_unfiltered.groupby(\"CellType\")[feature_columns_2].sum() \n",
    "grouped_sums_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 20\n",
    "\n",
    "# Create subplots with 2 rows and 1 column\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# MCF7 dataset\n",
    "total_sums_1 = grouped_sums_1.sum(axis=0)\n",
    "\n",
    "# Sort columns by total sum and pick top N\n",
    "top_columns_1 = total_sums_1.sort_values(ascending=False).head(top_n).index\n",
    "top_data_1 = grouped_sums_1[top_columns_1]\n",
    "\n",
    "# First subplot: MCF7 dataset\n",
    "top_data_1.T.plot(kind='bar', stacked=True, ax=axes[0])\n",
    "axes[0].set_title(\"Genes' Expression by Cell Condition - MCF7 Dataset\", fontsize=18)\n",
    "axes[0].set_xlabel('Genes')\n",
    "axes[0].set_ylabel('Total Counts')\n",
    "axes[0].legend(title='Cell Condition')\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# HCC dataset\n",
    "total_sums_2 = grouped_sums_2.sum(axis=0)\n",
    "\n",
    "# Sort columns by total sum and pick top N\n",
    "top_columns_2 = total_sums_2.sort_values(ascending=False).head(top_n).index\n",
    "top_data_2 = grouped_sums_2[top_columns_2]\n",
    "\n",
    "# Second subplot: HCC dataset\n",
    "top_data_2.T.plot(kind='bar', stacked=True, ax=axes[1])\n",
    "axes[1].set_title(\"Genes' Expression by Cell Condition - HCC Dataset\", fontsize=18)\n",
    "axes[1].set_xlabel('Genes')\n",
    "axes[1].set_ylabel('Total Counts')\n",
    "axes[1].legend(title='Cell Condition')\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Final layout adjustment\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get top genes from dataset 1\n",
    "total_sums = grouped_sums_1.sum(axis=0)\n",
    "top_genes = total_sums.sort_values(ascending=False).head(top_n).index\n",
    "top_HCC = set(top_genes) & set(df_HCC_unfiltered.columns)\n",
    "top_MCF7 = set(top_genes) & set(df_MCF7_unfiltered.columns)\n",
    "top_genes = list(top_HCC & top_MCF7)\n",
    "\n",
    "# 3. Subset both datasets\n",
    "df1_top = grouped_sums_1[top_genes].copy()\n",
    "df2_top = grouped_sums_2[top_genes].copy()\n",
    "\n",
    "# 4. Add 'Condition' column before melting\n",
    "df1_top['Condition'] = df1_top.index\n",
    "df2_top['Condition'] = df2_top.index\n",
    "\n",
    "# 5. Melt both to long format\n",
    "df1_long = df1_top.melt(id_vars='Condition', var_name='Gene', value_name='Count')\n",
    "df1_long['Dataset'] = 'MCF7 Dataset'\n",
    "df2_long = df2_top.melt(id_vars='Condition', var_name='Gene', value_name='Count')\n",
    "df2_long['Dataset'] = 'HCC Dataset'\n",
    "\n",
    "# 6. Combine both\n",
    "combined_long = pd.concat([df1_long, df2_long], ignore_index=True)\n",
    "\n",
    "# 7. Create composite category: Gene + Condition\n",
    "combined_long['Gene_Condition'] = combined_long['Gene'] + ' (' + combined_long['Condition'] + ')'\n",
    "\n",
    "# 8. Plot side-by-side bars\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.barplot(\n",
    "    data=combined_long,\n",
    "    x='Gene_Condition',\n",
    "    y='Count',\n",
    "    hue='Dataset',\n",
    "    palette=['blue', 'red']\n",
    ")\n",
    "\n",
    "# 9. Styling\n",
    "plt.title(\"Gene Expression by Condition — HCC Dataset vs MCF7 Dataset\", fontsize=16)\n",
    "plt.xlabel(\"Gene (Condition)\", fontsize=12)\n",
    "plt.ylabel(\"Total Counts\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Dataset')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HCC_unfiltered.drop(columns=\"CellType\", inplace=True)\n",
    "df_MCF7_unfiltered.drop(columns=\"CellType\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that some genes are more important than others to identify hypoxic cells since some are linked to a particular condition. This means that feature selection and dimensionality reduction might be very helpfuul to remove genes produced for both hypoxic and normal cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating correlation of samples and genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = 50\n",
    "top_genes_1 = df_MCF7_unfiltered.iloc[:, :-2].sum().sort_values(ascending=False).head(n_genes).index\n",
    "sampled_cells_1 = df_MCF7_unfiltered.sample(25)\n",
    "truncated_rows_1 = [i[12:27] for i in sampled_cells_1.index.tolist()]\n",
    "\n",
    "top_genes_2 = df_HCC_unfiltered.iloc[:, :-2].sum().sort_values(ascending=False).head(n_genes).index\n",
    "sampled_cells_2 = df_HCC_unfiltered.sample(25)\n",
    "truncated_rows_2 = [i[12:38] for i in sampled_cells_2.index.tolist()]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Heatmap for Dataset 1 (MCF7)\n",
    "sns.heatmap(sampled_cells_1[top_genes_1], ax=axes[0], cbar=True, cmap=\"coolwarm\")\n",
    "axes[0].set_title('Expression Heatmap: Top 20 Genes in Sampled Cells - MCF7 Dataset')\n",
    "axes[0].set_xlabel(\"Genes\")\n",
    "axes[0].set_ylabel(\"Sample Cells\")\n",
    "axes[0].set_yticklabels(truncated_rows_1, rotation=0)\n",
    "\n",
    "# Heatmap for Dataset 2 (HCC)\n",
    "sns.heatmap(sampled_cells_2[top_genes_2], ax=axes[1], cbar=True, cmap=\"coolwarm\")\n",
    "axes[1].set_title('Expression Heatmap: Top 20 Genes in Sampled Cells - HCC Dataset')\n",
    "axes[1].set_xlabel(\"Genes\")\n",
    "axes[1].set_ylabel(\"Sample Cells\")\n",
    "axes[1].set_yticklabels(truncated_rows_2, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Heatmap for Dataset 1 (MCF7)\n",
    "sns.heatmap(sampled_cells_1[top_genes_1].corr(), ax=axes[0], cbar=True, cmap=\"coolwarm\")\n",
    "axes[0].set_title('Gene correlation matrix: Top 20 Genes in Sampled Cells - MCF7 Dataset')\n",
    "axes[0].set_xlabel(\"Genes\")\n",
    "axes[0].set_ylabel(\"Genes\")\n",
    "\n",
    "# Heatmap for Dataset 2 (HCC)\n",
    "sns.heatmap(sampled_cells_2[top_genes_2].corr(), ax=axes[1], cbar=True, cmap=\"coolwarm\")\n",
    "axes[1].set_title('Gene correlation matrix: Top 20 Genes in Sampled Cells - HCC Dataset')\n",
    "axes[1].set_xlabel(\"Genes\")\n",
    "axes[1].set_ylabel(\"Genes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and compute distances for MCF7                                               ######################### CHECK BETTER AND DECIDE WHETHER TO KEEP HERE ##############################\n",
    "scaler = StandardScaler()\n",
    "df_scaled_1 = scaler.fit_transform(df_MCF7_unfiltered[top_genes_1].T)\n",
    "distance_matrix_1 = pdist(df_scaled_1, metric='correlation')\n",
    "distance_square_1 = squareform(distance_matrix_1)\n",
    "\n",
    "# Scale and compute distances for HCC\n",
    "df_scaled_2 = scaler.fit_transform(df_HCC_unfiltered[top_genes_2].T)\n",
    "distance_matrix_2 = pdist(df_scaled_2, metric='correlation')\n",
    "distance_square_2 = squareform(distance_matrix_2)\n",
    "\n",
    "# Create two clustermaps separately\n",
    "g1 = sns.clustermap(distance_square_1, cmap='coolwarm', xticklabels=top_genes_1, yticklabels=top_genes_1)\n",
    "g1.cax.set_position([.99, .08, .03, .74])\n",
    "g2 = sns.clustermap(distance_square_2, cmap='coolwarm', xticklabels=top_genes_2, yticklabels=top_genes_2)\n",
    "g2.cax.set_position([.99, .08, .03, .74])\n",
    "\n",
    "# Optional: improve layout\n",
    "g1.fig.suptitle('Gene Correlation Matrix - MCF7 Dataset (Top 20 Genes)', y=1.05, fontsize=16)\n",
    "g2.fig.suptitle('Gene Correlation Matrix - HCC Dataset (Top 20 Genes)', y=1.05, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 100 cells\n",
    "sampled_cells_1 = df_MCF7_unfiltered.sample(100)\n",
    "sampled_cells_2 = df_HCC_unfiltered.sample(100)\n",
    "\n",
    "# Select top 20 genes by total expression\n",
    "top_genes_1 = df_MCF7_unfiltered.iloc[:, :-2].sum().sort_values(ascending=False).head(20).index\n",
    "top_genes_2 = df_HCC_unfiltered.iloc[:, :-2].sum().sort_values(ascending=False).head(20).index\n",
    "\n",
    "# Extract expression data for top genes\n",
    "sampled_data_1 = sampled_cells_1[top_genes_1]\n",
    "sampled_data_2 = sampled_cells_2[top_genes_2]\n",
    "\n",
    "# Compute sample-to-sample correlation\n",
    "sample_corr_1 = sampled_data_1.corr(method='pearson') if sampled_data_1.shape[0] < sampled_data_1.shape[1] else sampled_data_1.T.corr()\n",
    "sample_corr_2 = sampled_data_2.corr(method='pearson') if sampled_data_2.shape[0] < sampled_data_2.shape[1] else sampled_data_2.T.corr()\n",
    "\n",
    "# Truncate sample names\n",
    "truncated_names_1 = [idx[12:27] for idx in sample_corr_1.index]\n",
    "truncated_names_2 = [idx[12:38] for idx in sample_corr_2.index]\n",
    "\n",
    "# Apply truncated names to both axes\n",
    "sample_corr_1.index = truncated_names_1\n",
    "sample_corr_1.columns = truncated_names_1\n",
    "sample_corr_2.index = truncated_names_2\n",
    "sample_corr_2.columns = truncated_names_2\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 14))\n",
    "\n",
    "# MCF7 correlation heatmap\n",
    "sns.heatmap(sample_corr_1, ax=axes[0], cmap=\"coolwarm\", cbar=True)\n",
    "axes[0].set_title(\"Sample Correlation Heatmap - MCF7 (Top 20 Genes)\")\n",
    "axes[0].set_xlabel(\"Samples\")\n",
    "axes[0].set_ylabel(\"Samples\")\n",
    "\n",
    "# HCC correlation heatmap\n",
    "sns.heatmap(sample_corr_2, ax=axes[1], cmap=\"coolwarm\", cbar=True)\n",
    "axes[1].set_title(\"Sample Correlation Heatmap - HCC (Top 20 Genes)\")\n",
    "axes[1].set_xlabel(\"Samples\")\n",
    "axes[1].set_ylabel(\"Samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples are not really independent as they should be, as can be seen from bright heatmap colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: OUTLIER DETECTION WITH ISOLATION FOREST on MCF7 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen below, traditional statistical tests relying on IQR and zscore classify too many points as outliers due to high-dimensionality and sparsity issues. Therefore, we try to implement a more complex model for outlier detection based on random forests, called isolation forest as implemented by scikit-learn.\\\n",
    "This ML algorithm, ISOLATION FOREST, trains is an ensemble of trees for which at each step, a selection of a random feature is performed and then a split value is randomly selected leading to a recusrive partitioning of the feature space, which ends when all samples occupy a different leaf, all leaves are pure. The number of such splits required to arrive (from the first split) to a pure leaf is a measure of normality of the sample and thus used as the model's decision function. This happens because, citing scikit documentation, \"Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score method\n",
    "from scipy.stats import zscore\n",
    "z_scores = np.abs(zscore(df_MCF7_unfiltered))\n",
    "df_no_outliers = df_MCF7_unfiltered[(z_scores < 3).all(axis=1)]\n",
    "print(f\"Removed {df_MCF7_unfiltered.shape[0] - df_no_outliers.shape[0]} outliers using Z-score method.\")\n",
    "\n",
    "#IQR method\n",
    "Q1 = df_MCF7_unfiltered.quantile(0.25)\n",
    "Q3 = df_MCF7_unfiltered.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Keep rows within bounds\n",
    "df_iqr_no_outliers = df_MCF7_unfiltered[~((df_MCF7_unfiltered < lower_bound) | (df_MCF7_unfiltered > upper_bound)).any(axis=1)]\n",
    "print(f\"Removed {df_MCF7_unfiltered.shape[0] - df_iqr_no_outliers.shape[0]} outliers using IQR method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out samples with more than 90% zeros\n",
    "sparsity_threshold = 0.90\n",
    "non_zero_counts = (df_HCC_unfiltered > 0).sum(axis=1)\n",
    "sample_sparsity = 1 - (non_zero_counts / df_HCC_unfiltered.shape[1])\n",
    "print(sample_sparsity)\n",
    "filtered_samples = df_HCC_unfiltered[sample_sparsity <= sparsity_threshold]\n",
    "\n",
    "# Show how many samples were retained\n",
    "print(\"Samples retained:\", filtered_samples.shape[0])\n",
    "print(\"Samples removed:\", df_HCC_unfiltered.shape[0] - filtered_samples.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(sample_sparsity)-np.std(sample_sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out samples with more than 90% zeros\n",
    "sparsity_threshold = 0.90\n",
    "non_zero_counts = (df_HCC_unfiltered.T > 0).sum(axis=1)\n",
    "genes_sparsity = 1 - (non_zero_counts / df_HCC_unfiltered.T.shape[1])\n",
    "print(sample_sparsity)\n",
    "filtered_genes = df_HCC_unfiltered.T[genes_sparsity <= sparsity_threshold]\n",
    "\n",
    "# Show how many samples were retained\n",
    "print(\"Samples retained:\", filtered_genes.shape[0])\n",
    "print(\"Samples removed:\", df_HCC_unfiltered.T.shape[0] - filtered_genes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(sample_sparsity)-np.std(sample_sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the distributions are very much skewed and dataset is very sparse, traditional quartiles and disitribution tests lead to almost all datapoints being considered as outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we first apply standrdization to the featured and then apply PCA to the MCF7 (easier) dataset to evalaute how far different data representations can influence the findings of siolation forest. We train the Isolation Forest algorithm using 100 components and visualise the results in 2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "#data processing\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_MCF7_unfiltered)\n",
    "\n",
    "# Reduce to 2D with PCA for visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "#pca for data compression and outlier detection\n",
    "pca_out = PCA(n_components=2500, random_state=42)\n",
    "pca_result_out = pca.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Isolation Forest to data scaled \n",
    "iso_forest = IsolationForest(n_estimators=100, max_features=1, max_samples=100, contamination=\"auto\", n_jobs=10, random_state=4)\n",
    "outlier_labels_std = iso_forest.fit_predict(df_scaled) #fit the model using only the standardized data\n",
    "\n",
    "# Add results back to a DataFrame\n",
    "df_result = pd.DataFrame(df_scaled, columns=df_MCF7_unfiltered.columns)\n",
    "df_result['outlier'] = outlier_labels_std == -1  # True if outlier\n",
    "df_result['PC1'] = pca_result[:, 0]\n",
    "df_result['PC2'] = pca_result[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_result.loc[~df_result['outlier'], 'PC1'],\n",
    "            df_result.loc[~df_result['outlier'], 'PC2'],\n",
    "            c='blue', label='Inliers', alpha=0.6)\n",
    "plt.scatter(df_result.loc[df_result['outlier'], 'PC1'],\n",
    "            df_result.loc[df_result['outlier'], 'PC2'],\n",
    "            c='red', label='Outliers', alpha=0.8)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Outlier Detection in MCF7 standardized Data (Isolation Forest)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Isolation Forest to principal components\n",
    "iso_forest = IsolationForest(n_estimators=100, max_features=1, max_samples=100, contamination=\"auto\", n_jobs=10, random_state=4)\n",
    "outlier_labels = iso_forest.fit_predict(pca_result_out)\n",
    "\n",
    "# Add results back to a DataFrame\n",
    "df_result = pd.DataFrame(df_scaled, columns=df_MCF7_unfiltered.columns)\n",
    "df_result['outlier'] = outlier_labels == -1  # True if outlier\n",
    "df_result['PC1'] = pca_result[:, 0]\n",
    "df_result['PC2'] = pca_result[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_result.loc[~df_result['outlier'], 'PC1'],\n",
    "            df_result.loc[~df_result['outlier'], 'PC2'],\n",
    "            c='blue', label='Inliers', alpha=0.6)\n",
    "plt.scatter(df_result.loc[df_result['outlier'], 'PC1'],\n",
    "            df_result.loc[df_result['outlier'], 'PC2'],\n",
    "            c='red', label='Outliers', alpha=0.8)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Outlier Detection (Isolation Forest) in MCF7 Data after PCA with 200 comps')\n",
    "plt.legend()\n",
    "plt.xlim(-100, 130)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the contaimnation = \"auto\" parameter as is usually done in unsupervised analysis, gives very poor results classifying most of the points as outliers or none of the points probably because of the same sparsity and scaling issues discussed above. Moreover, the results are not consistent since they depend heavily on the data representation as can be seen from teh fact that the dataset after PCA a majority of points considered outliers and before it, instead no point is deemed to be an outlier.Therefore, we suspect method not be highly reliable for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to explore\n",
    "contamination_values = [0.01, 0.05, \"auto\"] #although the analysis is unsupervised and auto is set explcitly to 0.01,0.05, it is done just to see how the algorithm works and how much\n",
    "                                            # this affects the outliers predicted. Answer: dependence is too significant and so no really reliable for blind detection \n",
    "max_samples_values = [0.4, 0.5, 0.75, 'auto']\n",
    "\n",
    "# Set up subplot grid\n",
    "fig, axes = plt.subplots(len(contamination_values), len(max_samples_values), figsize=(18, 12))\n",
    "fig.suptitle('Isolation Forest Outlier Detection: Various Contamination & Max_Samples', fontsize=16)\n",
    "\n",
    "for i, contamination in enumerate(contamination_values):\n",
    "    for j, max_samples in enumerate(max_samples_values):\n",
    "        # Fit Isolation Forest\n",
    "        iso_forest = IsolationForest(\n",
    "            n_estimators=100,\n",
    "            max_features=1,\n",
    "            max_samples=max_samples,\n",
    "            contamination=contamination,\n",
    "            n_jobs=-1,\n",
    "            random_state=4\n",
    "        )\n",
    "        outlier_labels = iso_forest.fit_predict(pca_result_out)\n",
    "        outliers = outlier_labels == -1\n",
    "        \n",
    "        # Prepare DataFrame for plotting\n",
    "        df_result = pd.DataFrame({\n",
    "            'PC1': pca_result[:, 0],\n",
    "            'PC2': pca_result[:, 1],\n",
    "            'outlier': outliers\n",
    "        })\n",
    "        \n",
    "        ax = axes[i, j]\n",
    "        ax.scatter(df_result.loc[~df_result['outlier'], 'PC1'],\n",
    "                   df_result.loc[~df_result['outlier'], 'PC2'],\n",
    "                   c='blue', label='Inliers', alpha=0.5)\n",
    "        ax.scatter(df_result.loc[df_result['outlier'], 'PC1'],\n",
    "                   df_result.loc[df_result['outlier'], 'PC2'],\n",
    "                   c='red', label='Outliers', alpha=0.8)\n",
    "        ax.set_title(f\"Contam: {contamination}, MaxSamples: {max_samples}\")\n",
    "        ax.set_xlim(-100, 130)\n",
    "        ax.set_xlabel(\"PC1\")\n",
    "        ax.set_ylabel(\"PC2\")\n",
    "        ax.grid(True)\n",
    "\n",
    "# Only show legend in one plot\n",
    "for i in range(len(contamination_values)):\n",
    "    for j in range(len(max_samples_values)):\n",
    "        axes[i,j].legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we try plotting the deciision function for isolation forest to gain more intel on the model's behaviour\n",
    "clf = IsolationForest(max_samples=\"auto\", contamination=\"auto\", n_estimators=100, max_features=1, random_state=4) \n",
    "clf.fit(pca_result[:,:2])\n",
    "y = clf.predict(pca_result[:,:2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    pca_result[:,:2],\n",
    "    response_method=\"decision_function\",\n",
    "    alpha=0.5,\n",
    "    cmap=plt.cm.coolwarm,\n",
    "    ax =ax\n",
    ")\n",
    "colors = np.where(y == -1, \"blue\", \"red\")\n",
    "scatter = disp.ax_.scatter(pca_result[:, 0], pca_result[:, 1], c=colors, s=20, edgecolor=\"k\")\n",
    "\n",
    "# Plot formatting\n",
    "# Title and labels\n",
    "ax.set_title(\"Isolation Forest Decision Boundary on PCA-Reduced Data\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Create legend manually\n",
    "import matplotlib.patches as mpatches\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color='red', label='Inliers'),\n",
    "    mpatches.Patch(color='blue', label='Outliers')\n",
    "]\n",
    "ax.legend(handles=legend_handles, title=\"Predicted Class\")\n",
    "\n",
    "# Add colorbar correctly\n",
    "cb = plt.colorbar(disp.ax_.collections[0], ax=ax, shrink=0.6)\n",
    "cb.set_label('Decision Function Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sum(y==1)} out of {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = df_HCC_unfiltered.T.columns\n",
    "conditions = []\n",
    "for name in sample_names:\n",
    "    if \"Norm\" in name:\n",
    "        conditions.append(\"Norm\")\n",
    "    elif \"Hypo\" in name:\n",
    "        conditions.append(\"Hypo\")\n",
    "    else:\n",
    "        conditions.append(\"Unknown\")\n",
    "\n",
    "colors_HCC = [\"blue\" if c == \"Norm\" else \"red\" if c == \"Hypo\" else \"gray\" for c in conditions]\n",
    "condition_labels_HCC = np.array([0 if c == \"Norm\" else 1 if c == \"Hypo\" else 2 for c in conditions])\n",
    "\n",
    "sample_names = df_MCF7_unfiltered.T.columns\n",
    "conditions = []\n",
    "for name in sample_names:\n",
    "    if \"Norm\" in name:\n",
    "        conditions.append(\"Norm\")\n",
    "    elif \"Hypo\" in name:\n",
    "        conditions.append(\"Hypo\")\n",
    "    else:\n",
    "        conditions.append(\"Unknown\")\n",
    "\n",
    "colors_MCF7 = [\"blue\" if c == \"Norm\" else \"red\" if c == \"Hypo\" else \"gray\" for c in conditions]\n",
    "condition_labels_MCF7 = np.array([0 if c == \"Norm\" else 1 if c == \"Hypo\" else 2 for c in conditions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(condition_labels_MCF7[y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(df):\n",
    "    sample_names = df.T.columns\n",
    "    conditions = []\n",
    "    for name in sample_names:\n",
    "        if \"Norm\" in str(name):\n",
    "            conditions.append(0)\n",
    "        elif \"Hypo\" in str(name):\n",
    "            conditions.append(1)\n",
    "\n",
    "    colors = [\"blue\" if c == 0 else \"red\" for c in conditions]\n",
    "    return conditions, colors \n",
    "conditions, colors = extract_labels(df_HCC_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "estimator = MLPClassifier()\n",
    "\n",
    "# define parameter distribution\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (200,), (50, 50), (100, 100), (200, 200)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': loguniform(1e-5, 1),\n",
    "    'batch_size': [None, 10, 20, 50],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [200, 500, 1000]\n",
    "}\n",
    "\n",
    "# search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_distributions=param_dist,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# HCC\n",
    "random_search.fit(df_HCC_unfiltered, conditions)\n",
    "\n",
    "# best model HCC\n",
    "best_mlp_HCC = random_search.best_estimator_\n",
    "best_params_HCC = random_search.best_params_\n",
    "best_score_HCC = random_search.best_score_\n",
    "\n",
    "# # MCF7\n",
    "# random_search.fit(X_train_MCF7, y_train_MCF7)\n",
    "# # best model MCF7\n",
    "# best_mlp_MCF7 = random_search.best_estimator_\n",
    "# best_params_MCF7 = random_search.best_params_\n",
    "# best_score_MCF7 = random_search.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from above analysis, the results of Isolation Forest appear to be qualitatively/graphically sensible given the plots obtained and provide a good way to detect outliers, when in possession of estimates on the share of outliers in the dataset.\n",
    "However, the outliers found by the algorithm very much depend on the parmeters used, especially on the contamination parameter, (literally the approximate proportion of outliers) which requires previous knowledge of outlier presence or of anomalies because of some bilogical reason. Since there is no good reason to suppose/assume that any specfic quantity of anomalies were produced in the data, this method does not provide enough evidence for removing or handling differently some datapoints.\\\n",
    "Moreover, Isolation Forest algorithm is also very much dependent upon the data representation since it partitions the feature space. Therefore, if we had applied it to the UMAP or TSNE mebedding, using the same or a similar number of components, we would have gotten completely different results.\\\n",
    "FInally, the method is discarded for future analysis because of the above reasons and the presence of better alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we will attempt to identify samples corresponding to noise or outliers in the unsupervised analysis file by resorting to more general techniques, namely silhouette score graphs and DBSCAN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
